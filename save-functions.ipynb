{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que Grava o Dataframe no Data Lake criando uma Delta Table particionado pela data de carga. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeInBlobDatabricks(df,path,schema,tabela,format_write,modo):\n",
    "    try:\n",
    "        df = df.withColumn(\"dt_folder\", current_date().cast(\"date\"))\n",
    "        (df.write.format(format_write)\n",
    "        .mode(modo)\n",
    "        .partitionBy('dt_folder')\n",
    "        .option(\"mergeSchema\", \"true\")\n",
    "        .option(\"path\", path)\n",
    "        .saveAsTable(schema+tabela))\n",
    "        return True\n",
    "    except Exception as ex:\n",
    "        return ex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que Grava o dataframe no Synapse por PolyBase, utilizando como método de autenticação Managed Service Identity seguindo as práticas de segurança - KeyVault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grava_no_dw(df, tabela, dw_conexao, temp):\n",
    "    spark.conf.set(\"fs.azure.account.auth.type.meudatalake.dfs.core.windows.net\", \"OAuth\")\n",
    "    spark.conf.set(\"fs.azure.account.oauth.provider.type.meudatalake.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "    spark.conf.set(\"fs.azure.account.oauth2.client.id.meudatalake.dfs.core.windows.net\", dbutils.secrets.get(scope = \"key-vault\", key = \"clientid\"))\n",
    "    spark.conf.set(\"fs.azure.account.oauth2.client.secret.meudatalake.dfs.core.windows.net\", dbutils.secrets.get(scope = \"key-vault\", key = \"secret\"))\n",
    "    spark.conf.set(\"fs.azure.account.oauth2.client.endpoint.meudatalake.dfs.core.windows.net\", \"https://login.microsoftonline.com/\"+dbutils.secrets.get(scope = \"key-vault\", key = \"DiretorioId\")+\"/oauth2/token\")\n",
    "    \n",
    "    df.write.format(\"com.databricks.spark.sqldw\")\n",
    "    .option(\"url\", dw_conexao)\n",
    "    .option(\"useAzureMSI\", \"true\")\n",
    "    .option(\"dbTable\", tabela)\n",
    "    .mode(\"append\")\n",
    "    .option(\"tempDir\", temp)\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46efb5c2514dfc5717769b877d282e38a35a6ce10818c558da1b276ffeedc640"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
